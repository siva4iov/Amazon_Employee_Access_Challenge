{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siva4iov/Amazon_Employee_Access_Challenge/blob/main/Amazon_com_Employee_Access_Challenge_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c6e71a8",
      "metadata": {
        "id": "8c6e71a8"
      },
      "source": [
        "# Описание используемых алгоритмов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1073175a",
      "metadata": {
        "id": "1073175a"
      },
      "source": [
        "## train_test_split\n",
        "Используем train_test_split для создания валидационной выборки, важно использовать stratify, так как данные с очень нарушенным балансом, нужно чтобы одинаковое кол-во экземпляров класса попало и в тренировочную и валидационную"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbbdb893",
      "metadata": {
        "id": "fbbdb893"
      },
      "source": [
        "# GaussianNB\n",
        "Для начала возьмем простые модели, позволяющие определить на что вообще можно расчитывать, гауссова наивная модель мне кажется одна из самых простейших моделей(не считая линейных) которые мы можем попробовать"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07b49255",
      "metadata": {
        "id": "07b49255"
      },
      "source": [
        "# GridSearchCV\n",
        "Для нахождения оптимальных гиперпараметров, будем использовать GridSearch, для отбора fold'ов мы использовали **StratifiedShuffleSplit**, причиной этого было, что нам нужно равное распределение меньшего класса по fold'ам, а также, предпологалось использовать для **GridSearch** не всю выборку, этот алгоритм это позволяет. Но в конечном итоге мы решили использовать байесовскую модель, а она довольная легкая и можно было брать всю выборку.\n",
        "\n",
        "Параметрами **GridSearch** было **var_smoothing**, точнее доля дисперсии признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45019025",
      "metadata": {
        "id": "45019025"
      },
      "source": [
        "### GaussianNB score\n",
        "Точность на вал выборке была 0.94, но при этом точность на данных, содержащих метку меньшего класса, точность 0.\n",
        "То есть модель сильно переобучилась и в итоге практически просто выдает константу 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb8b7a48",
      "metadata": {
        "id": "cb8b7a48"
      },
      "source": [
        "### Варианты решения\n",
        "Из-за того, что доля меньшего класса около 5%, следует использовать другую стратегию.\n",
        "\n",
        "Мы предположили нескольлко вариантов решения:\n",
        "\n",
        "    - Использовать другую модель, которая лучше подходит для таких данных, например дерево решений\n",
        "    - Использовать undersamling или oversampling\n",
        "    - Использовать для отбора признаков другие метрики, которые лучше подходят для несбалансированных данных"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ead03533",
      "metadata": {
        "id": "ead03533"
      },
      "source": [
        "# GradientBoostingClassifier\n",
        "\n",
        "Мы решили использовать сразу бустинг, вместо просто дерева, но начали с модели от sklearn. У нее намного меньше полезных фич, в отличие от XGBoost или CatBoost.\n",
        "\n",
        "Параметрами gridsearch мы использовали только learning_rate и n_estimators, так как это самые значимые гиперпараметры.\n",
        "\n",
        "Также, тут для отбора fold'ов уже используем **StratifiedKFold**, так как это не позволит данным в fold'ах пересекаться, а нам нужны все наши значения, особенно с меткой 0. Плюс ко всему, мы используем 5 фолдов, опять же чтобы оценка была сбалансированнее и мы использовали больше данных.\n",
        "\n",
        "Мы опробовали несколько метрик, таких как *recall, precision, f1*, но в итоге остановились на **ROC_AUC**. К тому же только тут мы заметили, что для оценки на kaggle используется эта же метрика.\n",
        "\n",
        "Это дало небольшой прирост в точности на данных с метрикой 0, но этого все равно недостаточно.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48ef6de5",
      "metadata": {
        "id": "48ef6de5"
      },
      "source": [
        "# Oversampling\n",
        "\n",
        "Мы решили не обрезать данные, а синтезировать дополнительные.\n",
        "\n",
        "Метод был выбран **SMOTE** из модуля **imblearn**, со значением k_neighbors = 4, мы попробовали брать значение и поменьше, но это не дало прироста в качестве.\n",
        "\n",
        "На всякий случай, мы дополнительно прогнали **GridSearch** на пересэмплированных данных, лкчшие гиперпараметры все равно остались прежними\n",
        "\n",
        "Точность на значениях с меткой 0, значительно выросло. Мы решили сделать submission на kaggle, результат оказался уже довольно неплохой, **0.80229**. По большей части это вызванно тем, что после того как мы осознали что метрика для submission *roc_auc*,\n",
        "мы стали использовать значения predict_proba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eea957a",
      "metadata": {
        "id": "3eea957a"
      },
      "source": [
        "# Catboost \n",
        "\n",
        "На этом этапе мы решили перейти к более продвинутым моделям, таким как **catboost**.\n",
        "\n",
        "Cперва мы решили найти лучший learning_rate посредством gridsearch, модель взяли с 500 итерациями для ускорения процесса, как функцию потерь мы взяли КроссЭнтропию, это хорошая практика для данных с таким распределением.\n",
        "\n",
        "Лучшим значением learning_rate стало 0.1, можно было бы дополнительно пройти gridsearch и попробовать значения {0.05, 0.2},\n",
        "но мы посчитали это излишним, так как мы не гонимся за улучшением сотых долей результата.\n",
        "\n",
        "Как модель для предсказаний мы взяли модель с 1000 итераций, потому что с большим значением пришлось бы довольно ждать.\n",
        "\n",
        "Эта модель выдала очень хорошую оценку на валидационной выборке  -  **0.95172**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f018b90e",
      "metadata": {
        "id": "f018b90e"
      },
      "source": [
        "# Результат\n",
        "\n",
        "Финальная оценка на kaggle равна -  **0.87788**\n",
        "При этом лучшая оценка лидерборда -  **0.92964**\n",
        "Результат показался нам довольно неплохим и мы остались удовлетворены таким результатом."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "Amazon.com - Employee Access Challenge Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}